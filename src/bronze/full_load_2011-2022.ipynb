{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef28e438-0f9f-427d-a2a9-acdd88bf7245",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Bronze Load - Yellow Taxi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27085088-e41d-4f05-8333-4448afe6299f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37ddd96c-b271-4e06-b5a9-bc68c089b1c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, \"../lib/\")\n",
    "\n",
    "from utils import import_schema, export_schema, table_exists\n",
    "\n",
    "def cast_yellow_taxi_data(df):\n",
    "\n",
    "    return (df\n",
    "        .withColumn(\"VendorID\", col(\"VendorID\").cast(ByteType()))\n",
    "        .withColumn(\"passenger_count\", col(\"passenger_count\").cast(ByteType()))\n",
    "        .withColumn(\"trip_distance\", col(\"trip_distance\").cast(\"double\"))\n",
    "        .withColumn(\"RatecodeID\", col(\"RatecodeID\").cast(ByteType()))\n",
    "        .withColumn(\"PULocationID\", col(\"PULocationID\").cast(ShortType()))\n",
    "        .withColumn(\"DOLocationID\", col(\"DOLocationID\").cast(ShortType()))\n",
    "        .withColumn(\"payment_type\", col(\"payment_type\").cast(ByteType()))\n",
    "        .withColumn(\"fare_amount\", col(\"fare_amount\").cast(DecimalType(10, 2)))\n",
    "        .withColumn(\"extra\", col(\"extra\").cast(DecimalType(7, 2)))\n",
    "        .withColumn(\"mta_tax\", col(\"mta_tax\").cast(DecimalType(5, 2)))\n",
    "        .withColumn(\"tip_amount\", col(\"tip_amount\").cast(DecimalType(12, 2)))\n",
    "        .withColumn(\"tolls_amount\", col(\"tolls_amount\").cast(DecimalType(7, 2)))\n",
    "        .withColumn(\"improvement_surcharge\", col(\"improvement_surcharge\").cast(DecimalType(3, 2)))\n",
    "        .withColumn(\"total_amount\", col(\"total_amount\").cast(DecimalType(10, 2)))\n",
    "        .withColumn(\"congestion_surcharge\", col(\"congestion_surcharge\").cast(DecimalType(4, 2)))\n",
    "        .withColumn(\"airport_fee\", col(\"airport_fee\").cast(DecimalType(3, 2))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "205ef65a-b3aa-4340-bcaf-e9fa99f90425",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.parquet.enableVectorizedReader\", \"false\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db7e65cd-d40c-4df8-bcef-734e24cef8f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DecimalType, ByteType, ShortType\n",
    "\n",
    "catalog = \"bronze\"\n",
    "schema = \"taxi\"\n",
    "table_name = \"yellow_taxi\"\n",
    "path = f\"/Volumes/raw/{schema}/{table_name}\"\n",
    "\n",
    "df_schema = import_schema(table_name)\n",
    "\n",
    "for year in range(2011, 2022):\n",
    "    for month in range(1, 13):\n",
    "        file_path = f\"{year}/yellow_tripdata_{year}-{month:02d}.parquet\"\n",
    "        df = spark.read.format('parquet').load(f\"{path}/{file_path}\")\n",
    "\n",
    "        df_casted = cast_yellow_taxi_data(df)\n",
    "\n",
    "        if not table_exists(spark, catalog, schema, table_name):\n",
    "            df_casted.write.format(\"delta\").mode(\"overwrite\").saveAsTable(f\"{catalog}.{schema}.{table_name}\")\n",
    "        else:\n",
    "            df_casted.write.format(\"delta\").mode(\"append\").saveAsTable(f\"{catalog}.{schema}.{table_name}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 6317235037723853,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "full_load_2011-2022",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
