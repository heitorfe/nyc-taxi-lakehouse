{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45060f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "578it [00:01, 334.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas em todos os arquivos parquet: 3945621967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow\n",
    "import pyarrowfs_adlgen2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "ADLS_NAME = os.getenv(\"ADLS_NAME\")\n",
    "ADLS_KEY =  os.getenv(\"ADLS_KEY\")\n",
    "directory = \"sources\"  # ou ajuste conforme necessário\n",
    "\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "json_path = \"parquet_row_counts.json\"\n",
    "\n",
    "# Carrega o dicionário existente ou cria um novo\n",
    "if os.path.exists(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        row_counts = json.load(f)\n",
    "else:\n",
    "    row_counts = {}\n",
    "\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Create the container client\n",
    "account_url = f\"https://{ADLS_NAME}.blob.core.windows.net\"\n",
    "credential = ADLS_KEY\n",
    "container_name = \"taxi\"  # Change if your container name is different\n",
    "\n",
    "handler = pyarrowfs_adlgen2.AccountHandler.from_account_name(ADLS_NAME, ADLS_KEY)\n",
    "fs = pyarrow.fs.PyFileSystem(handler)\n",
    "\n",
    "blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "blobs = container_client.list_blobs(name_starts_with='source/')\n",
    "for blob in tqdm(blobs):\n",
    "    if blob.name.endswith('.parquet') and blob.name not in row_counts:\n",
    "        pf = pq.ParquetFile(f\"taxi/{blob.name}\", filesystem=fs)\n",
    "        row_counts[blob.name] = pf.metadata.num_rows\n",
    "\n",
    "\n",
    "# Salva o dicionário atualizado\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(row_counts, f, indent=2)\n",
    "\n",
    "total_rows = sum(row_counts.values())\n",
    "print(f\"Total de linhas em todos os arquivos parquet: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_mm_yyyy(fname):\n",
    "    # Exemplo: source/yellow/2025/yellow_tripdata_2025-03.parquet\n",
    "    match = re.search(r'(\\d{4})-(\\d{2})', fname)\n",
    "    if match:\n",
    "        return f\"{match.group(2)}-{match.group(1)}\"\n",
    "    return fname\n",
    "\n",
    "yellow_schemas = {}\n",
    "yellow_schema_diffs = []\n",
    "\n",
    "# Percorra todos os arquivos do yellow_trip\n",
    "for blob in container_client.list_blobs(name_starts_with='source/yellow/'):\n",
    "    if blob.name.endswith('.parquet'):\n",
    "        pf = pq.ParquetFile(f\"taxi/{blob.name}\", filesystem=fs)\n",
    "        schema = pf.schema.to_arrow_schema()\n",
    "        yellow_schemas[blob.name] = schema\n",
    "\n",
    "# Ordena os arquivos por nome (que contém ano/mês)\n",
    "sorted_files = sorted(yellow_schemas.keys())\n",
    "\n",
    "prev_schema = None\n",
    "prev_fname = None\n",
    "for fname in sorted_files:\n",
    "    schema = yellow_schemas[fname]\n",
    "    if prev_schema is not None and schema != prev_schema:\n",
    "        added = [f for f in schema.names if f not in prev_schema.names]\n",
    "        removed = [f for f in prev_schema.names if f not in schema.names]\n",
    "        type_changes = []\n",
    "        for col in set(schema.names).intersection(prev_schema.names):\n",
    "            prev_type = str(prev_schema.field(col).type)\n",
    "            curr_type = str(schema.field(col).type)\n",
    "            if prev_type != curr_type:\n",
    "                type_changes.append({\n",
    "                    \"column\": col,\n",
    "                    \"from\": prev_type,\n",
    "                    \"to\": curr_type\n",
    "                })\n",
    "        yellow_schema_diffs.append({\n",
    "            \"from\": extract_mm_yyyy(prev_fname),\n",
    "            \"to\": extract_mm_yyyy(fname),\n",
    "            \"added_columns\": added,\n",
    "            \"removed_columns\": removed,\n",
    "            \"type_changes\": type_changes\n",
    "        })\n",
    "    prev_schema = schema\n",
    "    prev_fname = fname\n",
    "\n",
    "# Salva as diferenças em um arquivo JSON simples\n",
    "with open(\"schema_evolution//yellow_schema_diffs_simple.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(yellow_schema_diffs, f, indent=2, ensure_ascii=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7425636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total source/yellow de 2014 até 2025: 131\n",
      "Quantidade por ano:\n",
      "2014: 8\n",
      "2015: 12\n",
      "2016: 12\n",
      "2017: 12\n",
      "2018: 12\n",
      "2019: 12\n",
      "2020: 12\n",
      "2021: 12\n",
      "2022: 12\n",
      "2023: 12\n",
      "2024: 12\n",
      "2025: 3\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "with open(\"parquet_row_counts.json\", \"r\") as f:\n",
    "    count = f.read()\n",
    "\n",
    "\n",
    "    data = json.loads(count)\n",
    "\n",
    "\n",
    "    yellow_counts_by_year = Counter()\n",
    "    for k in data:\n",
    "        if k.startswith(\"source/yellow/2014\"):\n",
    "            yellow_counts_by_year[\"2014\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2015\"):\n",
    "            yellow_counts_by_year[\"2015\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2016\"):\n",
    "            yellow_counts_by_year[\"2016\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2017\"):\n",
    "            yellow_counts_by_year[\"2017\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2018\"):\n",
    "            yellow_counts_by_year[\"2018\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2019\"):\n",
    "            yellow_counts_by_year[\"2019\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2020\"):\n",
    "            yellow_counts_by_year[\"2020\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2021\"):\n",
    "            yellow_counts_by_year[\"2021\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2022\"):\n",
    "            yellow_counts_by_year[\"2022\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2023\"):\n",
    "            yellow_counts_by_year[\"2023\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2024\"):\n",
    "            yellow_counts_by_year[\"2024\"] += 1\n",
    "        elif k.startswith(\"source/yellow/2025\"):\n",
    "            yellow_counts_by_year[\"2025\"] += 1\n",
    "\n",
    "    total_yellow = sum(yellow_counts_by_year.values())\n",
    "    print(f\"Total source/yellow de 2014 até 2025: {total_yellow}\")\n",
    "    print(\"Quantidade por ano:\")\n",
    "    for year in sorted(yellow_counts_by_year):\n",
    "        print(f\"{year}: {yellow_counts_by_year[year]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "537fdfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do dataset: (9224788, 19)\n",
      "Colunas: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
      "\n",
      "Primeiras 5 linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:13:56</td>\n",
       "      <td>2018-05-01 00:22:46</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>230</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:23:26</td>\n",
       "      <td>2018-05-01 00:29:56</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:36:23</td>\n",
       "      <td>2018-05-01 00:48:26</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:26:12</td>\n",
       "      <td>2018-05-01 00:27:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.43</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:29:51</td>\n",
       "      <td>2018-05-01 00:30:02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2018-05-01 00:13:56   2018-05-01 00:22:46                1   \n",
       "1         1  2018-05-01 00:23:26   2018-05-01 00:29:56                1   \n",
       "2         1  2018-05-01 00:36:23   2018-05-01 00:48:26                2   \n",
       "3         1  2018-05-01 00:26:12   2018-05-01 00:27:05                1   \n",
       "4         1  2018-05-01 00:29:51   2018-05-01 00:30:02                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.6           1                  N           230            50   \n",
       "1            1.7           1                  N           263           239   \n",
       "2            2.6           1                  N           239           152   \n",
       "3            0.0           1                  N           145           145   \n",
       "4            0.0           1                  N           145           145   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1          8.0    0.5      0.5        1.85           0.0   \n",
       "1             1          7.5    0.5      0.5        2.00           0.0   \n",
       "2             1         12.0    0.5      0.5        1.00           0.0   \n",
       "3             1          2.5    0.5      0.5        9.63           0.0   \n",
       "4             2          2.5    0.5      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount congestion_surcharge airport_fee  \n",
       "0                    0.3         11.15                 None        None  \n",
       "1                    0.3         10.80                 None        None  \n",
       "2                    0.3         14.30                 None        None  \n",
       "3                    0.3         13.43                 None        None  \n",
       "4                    0.3          3.80                 None        None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_yellow_taxi_data(year_month, limit=None):\n",
    "    \"\"\"\n",
    "    Busca e retorna o dataset do yellow taxi para um determinado ano-mês do ADLS.\n",
    "    \n",
    "    Args:\n",
    "        year_month (str): Formato 'YYYY-MM' (ex: '2013-05')\n",
    "        limit (int, optional): Número máximo de linhas a retornar. Se None, retorna todas.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataset do yellow taxi\n",
    "    \"\"\"\n",
    "    # Constrói o caminho do arquivo\n",
    "    file_path = f\"source/yellow/{year_month[:4]}/yellow_tripdata_{year_month}.parquet\"\n",
    "    \n",
    "    # Lê o arquivo parquet do ADLS\n",
    "    pf = pq.ParquetFile(f\"taxi/{file_path}\", filesystem=fs)\n",
    "    \n",
    "    if limit:\n",
    "        # Lê apenas as primeiras 'limit' linhas\n",
    "        df = pf.read(use_pandas_metadata=True).slice(0, limit).to_pandas()\n",
    "    else:\n",
    "        # Lê o arquivo completo\n",
    "        df = pf.read().to_pandas()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Exemplo de uso: buscar dados de maio de 2013 (primeiras 1000 linhas)\n",
    "yellow_2013_05 = get_yellow_taxi_data('2018-05')\n",
    "print(f\"Shape do dataset: {yellow_2013_05.shape}\")\n",
    "print(f\"Colunas: {list(yellow_2013_05.columns)}\")\n",
    "print(f\"\\nPrimeiras 5 linhas:\")\n",
    "yellow_2013_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4515b86e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9224788"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yellow_2013_05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c8a12e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de memória em todos os arquivos parquet: 34.506272 GBs\n"
     ]
    }
   ],
   "source": [
    "total_mem = 0\n",
    "\n",
    "# Recrie o iterador de blobs\n",
    "blobs = container_client.list_blobs(name_starts_with='source/')\n",
    "\n",
    "for blob in blobs:\n",
    "    # print(blob.name)\n",
    "    total_mem += blob.size\n",
    "\n",
    "print(f\"Total de memória em todos os arquivos parquet: {total_mem/(1024)**3:2f} GBs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e27dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
