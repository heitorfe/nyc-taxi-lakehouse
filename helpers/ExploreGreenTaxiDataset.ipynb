{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45060f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "578it [00:01, 328.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de linhas em todos os arquivos parquet: 3945621967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import pyarrow\n",
    "import pyarrowfs_adlgen2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "ADLS_NAME = os.getenv(\"ADLS_NAME\")\n",
    "ADLS_KEY =  os.getenv(\"ADLS_KEY\")\n",
    "directory = \"sources\"  # ou ajuste conforme necessário\n",
    "\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "json_path = \"parquet_row_counts.json\"\n",
    "\n",
    "# Carrega o dicionário existente ou cria um novo\n",
    "if os.path.exists(json_path):\n",
    "    with open(json_path, \"r\") as f:\n",
    "        row_counts = json.load(f)\n",
    "else:\n",
    "    row_counts = {}\n",
    "\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Create the container client\n",
    "account_url = f\"https://{ADLS_NAME}.blob.core.windows.net\"\n",
    "credential = ADLS_KEY\n",
    "container_name = \"taxi\"  # Change if your container name is different\n",
    "\n",
    "handler = pyarrowfs_adlgen2.AccountHandler.from_account_name(ADLS_NAME, ADLS_KEY)\n",
    "fs = pyarrow.fs.PyFileSystem(handler)\n",
    "\n",
    "blob_service_client = BlobServiceClient(account_url=account_url, credential=credential)\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "blobs = container_client.list_blobs(name_starts_with='source/')\n",
    "for blob in tqdm(blobs):\n",
    "    if blob.name.endswith('.parquet') and blob.name not in row_counts:\n",
    "        pf = pq.ParquetFile(f\"taxi/{blob.name}\", filesystem=fs)\n",
    "        row_counts[blob.name] = pf.metadata.num_rows\n",
    "\n",
    "\n",
    "# Salva o dicionário atualizado\n",
    "with open(json_path, \"w\") as f:\n",
    "    json.dump(row_counts, f, indent=2)\n",
    "\n",
    "total_rows = sum(row_counts.values())\n",
    "print(f\"Total de linhas em todos os arquivos parquet: {total_rows}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632254a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'from': '01-2014', 'to': '02-2014', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'improvement_surcharge', 'from': 'double', 'to': 'null'}]}\n",
      "{'from': '03-2014', 'to': '04-2014', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'improvement_surcharge', 'from': 'null', 'to': 'double'}]}\n",
      "{'from': '04-2014', 'to': '05-2014', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'improvement_surcharge', 'from': 'double', 'to': 'null'}]}\n",
      "{'from': '10-2014', 'to': '11-2014', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'improvement_surcharge', 'from': 'null', 'to': 'double'}]}\n",
      "{'from': '10-2015', 'to': '11-2015', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'double', 'to': 'int64'}]}\n",
      "{'from': '11-2015', 'to': '12-2015', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'int64', 'to': 'double'}]}\n",
      "{'from': '12-2015', 'to': '01-2016', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'congestion_surcharge', 'from': 'null', 'to': 'double'}]}\n",
      "{'from': '01-2016', 'to': '02-2016', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'congestion_surcharge', 'from': 'double', 'to': 'null'}]}\n",
      "{'from': '11-2016', 'to': '12-2016', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'double', 'to': 'int64'}]}\n",
      "{'from': '02-2017', 'to': '03-2017', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'int64', 'to': 'double'}]}\n",
      "{'from': '06-2017', 'to': '07-2017', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'double', 'to': 'int64'}]}\n",
      "{'from': '09-2017', 'to': '10-2017', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'int64', 'to': 'double'}]}\n",
      "{'from': '10-2017', 'to': '11-2017', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'double', 'to': 'int64'}]}\n",
      "{'from': '11-2017', 'to': '12-2017', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'int64', 'to': 'double'}]}\n",
      "{'from': '01-2018', 'to': '02-2018', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'double', 'to': 'int64'}]}\n",
      "{'from': '03-2018', 'to': '04-2018', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'int64', 'to': 'double'}]}\n",
      "{'from': '04-2018', 'to': '05-2018', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'trip_type', 'from': 'double', 'to': 'int64'}]}\n",
      "{'from': '06-2018', 'to': '07-2018', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'payment_type', 'from': 'int64', 'to': 'double'}, {'column': 'RatecodeID', 'from': 'int64', 'to': 'double'}, {'column': 'passenger_count', 'from': 'int64', 'to': 'double'}, {'column': 'trip_type', 'from': 'int64', 'to': 'double'}]}\n",
      "{'from': '09-2018', 'to': '10-2018', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'ehail_fee', 'from': 'null', 'to': 'double'}]}\n",
      "{'from': '12-2018', 'to': '01-2019', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'congestion_surcharge', 'from': 'null', 'to': 'double'}]}\n",
      "{'from': '08-2019', 'to': '09-2019', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'ehail_fee', 'from': 'double', 'to': 'null'}]}\n",
      "{'from': '01-2023', 'to': '02-2023', 'added_columns': [], 'removed_columns': [], 'type_changes': [{'column': 'payment_type', 'from': 'double', 'to': 'int64'}, {'column': 'PULocationID', 'from': 'int64', 'to': 'int32'}, {'column': 'RatecodeID', 'from': 'double', 'to': 'int64'}, {'column': 'passenger_count', 'from': 'double', 'to': 'int64'}, {'column': 'ehail_fee', 'from': 'null', 'to': 'double'}, {'column': 'DOLocationID', 'from': 'int64', 'to': 'int32'}, {'column': 'VendorID', 'from': 'int64', 'to': 'int32'}, {'column': 'store_and_fwd_flag', 'from': 'string', 'to': 'large_string'}, {'column': 'trip_type', 'from': 'double', 'to': 'int64'}]}\n",
      "{'from': '12-2024', 'to': '01-2025', 'added_columns': ['cbd_congestion_fee'], 'removed_columns': [], 'type_changes': []}\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import json\n",
    "import re\n",
    "\n",
    "def extract_mm_yyyy(fname):\n",
    "    # Exemplo: source/green/2025/green_tripdata_2025-03.parquet\n",
    "    match = re.search(r'(\\d{4})-(\\d{2})', fname)\n",
    "    if match:\n",
    "        return f\"{match.group(2)}-{match.group(1)}\"\n",
    "    return fname\n",
    "\n",
    "green_schemas = {}\n",
    "green_schema_diffs = []\n",
    "\n",
    "# Percorra todos os arquivos do green_trip\n",
    "for blob in container_client.list_blobs(name_starts_with='source/green/'):\n",
    "    if blob.name.endswith('.parquet'):\n",
    "        pf = pq.ParquetFile(f\"taxi/{blob.name}\", filesystem=fs)\n",
    "        schema = pf.schema.to_arrow_schema()\n",
    "        green_schemas[blob.name] = schema\n",
    "\n",
    "# Ordena os arquivos por nome (que contém ano/mês)\n",
    "sorted_files = sorted(green_schemas.keys())\n",
    "\n",
    "prev_schema = None\n",
    "prev_fname = None\n",
    "for fname in sorted_files:\n",
    "    schema = green_schemas[fname]\n",
    "    if prev_schema is not None and schema != prev_schema:\n",
    "        added = [f for f in schema.names if f not in prev_schema.names]\n",
    "        removed = [f for f in prev_schema.names if f not in schema.names]\n",
    "        type_changes = []\n",
    "        for col in set(schema.names).intersection(prev_schema.names):\n",
    "            prev_type = str(prev_schema.field(col).type)\n",
    "            curr_type = str(schema.field(col).type)\n",
    "            if prev_type != curr_type:\n",
    "                type_changes.append({\n",
    "                    \"column\": col,\n",
    "                    \"from\": prev_type,\n",
    "                    \"to\": curr_type\n",
    "                })\n",
    "        green_schema_diffs.append({\n",
    "            \"from\": extract_mm_yyyy(prev_fname),\n",
    "            \"to\": extract_mm_yyyy(fname),\n",
    "            \"added_columns\": added,\n",
    "            \"removed_columns\": removed,\n",
    "            \"type_changes\": type_changes\n",
    "        })\n",
    "    prev_schema = schema\n",
    "    prev_fname = fname\n",
    "\n",
    "# Salva as diferenças em um arquivo JSON simples\n",
    "with open(\"schema_evolution/green_schema_diffs_simple.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(green_schema_diffs, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "# Exemplo de visualização\n",
    "for diff in green_schema_diffs:\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537fdfb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape do dataset: (9224788, 19)\n",
      "Colunas: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee']\n",
      "\n",
      "Primeiras 5 linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VendorID</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>airport_fee</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:13:56</td>\n",
       "      <td>2018-05-01 00:22:46</td>\n",
       "      <td>1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>230</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.15</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:23:26</td>\n",
       "      <td>2018-05-01 00:29:56</td>\n",
       "      <td>1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>263</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>10.80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:36:23</td>\n",
       "      <td>2018-05-01 00:48:26</td>\n",
       "      <td>2</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>239</td>\n",
       "      <td>152</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>14.30</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:26:12</td>\n",
       "      <td>2018-05-01 00:27:05</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>13.43</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-05-01 00:29:51</td>\n",
       "      <td>2018-05-01 00:30:02</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>145</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.80</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
       "0         1  2018-05-01 00:13:56   2018-05-01 00:22:46                1   \n",
       "1         1  2018-05-01 00:23:26   2018-05-01 00:29:56                1   \n",
       "2         1  2018-05-01 00:36:23   2018-05-01 00:48:26                2   \n",
       "3         1  2018-05-01 00:26:12   2018-05-01 00:27:05                1   \n",
       "4         1  2018-05-01 00:29:51   2018-05-01 00:30:02                1   \n",
       "\n",
       "   trip_distance  RatecodeID store_and_fwd_flag  PULocationID  DOLocationID  \\\n",
       "0            1.6           1                  N           230            50   \n",
       "1            1.7           1                  N           263           239   \n",
       "2            2.6           1                  N           239           152   \n",
       "3            0.0           1                  N           145           145   \n",
       "4            0.0           1                  N           145           145   \n",
       "\n",
       "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
       "0             1          8.0    0.5      0.5        1.85           0.0   \n",
       "1             1          7.5    0.5      0.5        2.00           0.0   \n",
       "2             1         12.0    0.5      0.5        1.00           0.0   \n",
       "3             1          2.5    0.5      0.5        9.63           0.0   \n",
       "4             2          2.5    0.5      0.5        0.00           0.0   \n",
       "\n",
       "   improvement_surcharge  total_amount congestion_surcharge airport_fee  \n",
       "0                    0.3         11.15                 None        None  \n",
       "1                    0.3         10.80                 None        None  \n",
       "2                    0.3         14.30                 None        None  \n",
       "3                    0.3         13.43                 None        None  \n",
       "4                    0.3          3.80                 None        None  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_green_taxi_data(year_month, limit=None):\n",
    "    \"\"\"\n",
    "    Busca e retorna o dataset do green taxi para um determinado ano-mês do ADLS.\n",
    "    \n",
    "    Args:\n",
    "        year_month (str): Formato 'YYYY-MM' (ex: '2013-05')\n",
    "        limit (int, optional): Número máximo de linhas a retornar. Se None, retorna todas.\n",
    "    \n",
    "    Returns:\n",
    "        pandas.DataFrame: Dataset do green taxi\n",
    "    \"\"\"\n",
    "    # Constrói o caminho do arquivo\n",
    "    file_path = f\"source/green/{year_month[:4]}/green_tripdata_{year_month}.parquet\"\n",
    "    \n",
    "    # Lê o arquivo parquet do ADLS\n",
    "    pf = pq.ParquetFile(f\"taxi/{file_path}\", filesystem=fs)\n",
    "    \n",
    "    if limit:\n",
    "        # Lê apenas as primeiras 'limit' linhas\n",
    "        df = pf.read(use_pandas_metadata=True).slice(0, limit).to_pandas()\n",
    "    else:\n",
    "        # Lê o arquivo completo\n",
    "        df = pf.read().to_pandas()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Exemplo de uso: buscar dados de maio de 2013 (primeiras 1000 linhas)\n",
    "green_2013_05 = get_green_taxi_data('2018-05')\n",
    "print(f\"Shape do dataset: {green_2013_05.shape}\")\n",
    "print(f\"Colunas: {list(green_2013_05.columns)}\")\n",
    "print(f\"\\nPrimeiras 5 linhas:\")\n",
    "green_2013_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a12e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de memória em todos os arquivos parquet: 66.253575 GBs\n"
     ]
    }
   ],
   "source": [
    "total_mem = 0\n",
    "\n",
    "# Recrie o iterador de blobs\n",
    "blobs = container_client.list_blobs(name_starts_with='source/')\n",
    "\n",
    "for blob in blobs:\n",
    "    # print(blob.name)\n",
    "    total_mem += blob.size\n",
    "\n",
    "print(f\"Total de memória em todos os arquivos parquet: {total_mem/(1024)**3:2f} GBs\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
