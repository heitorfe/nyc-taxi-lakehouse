{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "faa429ba-b731-45fd-8d1d-86cbd114ccea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Demo: Delta Live Tables (DLT) com Yellow Taxi\n",
    "\n",
    "Este notebook demonstra como utilizar o **Delta Live Tables (DLT)** no Databricks para criar pipelines de ingestão e transformação de dados confiáveis, auditáveis e fáceis de manter. O DLT automatiza tarefas como gerenciamento de qualidade, versionamento e monitoramento dos dados.\n",
    "\n",
    "Vamos usar o dataset do yellow taxi, já utilizado no teste do Auto Loader, para mostrar como criar tabelas bronze (raw), silver (limpas) e gold (agregadas) com DLT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a78f51f1-018f-45c4-87ee-db6473eab21d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## O que é Delta Live Tables (DLT)?\n",
    "\n",
    "O Delta Live Tables é uma framework de pipelines declarativos da Databricks que permite:\n",
    "\n",
    "- Declarar tabelas e transformações como código Python ou SQL.\n",
    "- Gerenciar automaticamente a qualidade dos dados (expectations).\n",
    "- Versionar e monitorar pipelines de dados.\n",
    "- Automatizar ingestão, transformação e atualização de tabelas Delta.\n",
    "\n",
    "DLT é ideal para pipelines de ingestão incremental, ETL e preparação de dados para analytics e machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4a786300-fc8c-4433-96fd-3beb4faa25d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Pipeline DLT: Yellow Taxi\n",
    "\n",
    "Vamos criar um pipeline DLT com três camadas:\n",
    "\n",
    "- **Bronze:** ingestão bruta dos dados Parquet do yellow taxi.\n",
    "- **Silver:** limpeza e padronização dos dados.\n",
    "- **Gold:** agregação de métricas para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "32904eb2-ba79-4af5-9b97-2a95c35b4499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "-- Bronze layer: Raw data ingestion\n",
    "CREATE OR REFRESH STREAMING TABLE taxi_raw_records \n",
    "(CONSTRAINT valid_distance EXPECT (trip_distance > 0.0) ON VIOLATION DROP ROW)\n",
    "AS SELECT *\n",
    "FROM STREAM(samples.nyctaxi.trips);\n",
    "\n",
    "-- Silver layer 1: Flagged rides\n",
    "CREATE OR REFRESH STREAMING TABLE flagged_rides \n",
    "AS SELECT\n",
    "  date_trunc(\"week\", tpep_pickup_datetime) as week,\n",
    "  pickup_zip as zip, \n",
    "  fare_amount, trip_distance\n",
    "FROM\n",
    "  STREAM(LIVE.taxi_raw_records)\n",
    "WHERE ((pickup_zip = dropoff_zip AND fare_amount > 50) OR\n",
    "       (trip_distance < 5 AND fare_amount > 50));\n",
    "\n",
    "-- Silver layer 2: Weekly statistics\n",
    "CREATE OR REFRESH MATERIALIZED VIEW weekly_stats\n",
    "AS SELECT\n",
    "  date_trunc(\"week\", tpep_pickup_datetime) as week,\n",
    "  AVG(fare_amount) as avg_amount,\n",
    "  AVG(trip_distance) as avg_distance\n",
    "FROM\n",
    " live.taxi_raw_records\n",
    "GROUP BY week\n",
    "ORDER BY week ASC;\n",
    "\n",
    "-- Gold layer: Top N rides to investigate\n",
    "CREATE OR REPLACE MATERIALIZED VIEW top_n\n",
    "AS SELECT\n",
    "  weekly_stats.week,\n",
    "  ROUND(avg_amount,2) as avg_amount, \n",
    "  ROUND(avg_distance,3) as avg_distance,\n",
    "  fare_amount, trip_distance, zip \n",
    "FROM live.flagged_rides\n",
    "LEFT JOIN live.weekly_stats ON weekly_stats.week = flagged_rides.week\n",
    "ORDER BY fare_amount DESC\n",
    "LIMIT 3;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06d3e6dd-08db-4bc3-931e-867c2f3bbb94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Como executar este notebook\n",
    "\n",
    "1. Crie um pipeline Delta Live Tables no Databricks e aponte para este notebook.\n",
    "2. Execute o pipeline para ver as tabelas bronze, silver e gold sendo criadas e atualizadas automaticamente.\n",
    "3. Use as tabelas gold para análises e dashboards.\n",
    "\n",
    "**DLT** garante qualidade, rastreabilidade e automação no seu pipeline de dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "085f33a8-0d59-43df-9b8d-f86222facfa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "select * from lab.taxi.taxi_raw_records limit 5"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DLT",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
