{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fc6b324",
   "metadata": {},
   "source": [
    "# Demo: Delta Live Tables (DLT) com Yellow Taxi\n",
    "\n",
    "Este notebook demonstra como utilizar o **Delta Live Tables (DLT)** no Databricks para criar pipelines de ingestão e transformação de dados confiáveis, auditáveis e fáceis de manter. O DLT automatiza tarefas como gerenciamento de qualidade, versionamento e monitoramento dos dados.\n",
    "\n",
    "Vamos usar o dataset do yellow taxi, já utilizado no teste do Auto Loader, para mostrar como criar tabelas bronze (raw), silver (limpas) e gold (agregadas) com DLT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99de4314",
   "metadata": {},
   "source": [
    "## O que é Delta Live Tables (DLT)?\n",
    "\n",
    "O Delta Live Tables é uma framework de pipelines declarativos da Databricks que permite:\n",
    "\n",
    "- Declarar tabelas e transformações como código Python ou SQL.\n",
    "- Gerenciar automaticamente a qualidade dos dados (expectations).\n",
    "- Versionar e monitorar pipelines de dados.\n",
    "- Automatizar ingestão, transformação e atualização de tabelas Delta.\n",
    "\n",
    "DLT é ideal para pipelines de ingestão incremental, ETL e preparação de dados para analytics e machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572992d",
   "metadata": {},
   "source": [
    "## Pipeline DLT: Yellow Taxi\n",
    "\n",
    "Vamos criar um pipeline DLT com três camadas:\n",
    "\n",
    "- **Bronze:** ingestão bruta dos dados Parquet do yellow taxi.\n",
    "- **Silver:** limpeza e padronização dos dados.\n",
    "- **Gold:** agregação de métricas para análise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af54fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "from pyspark.sql.functions import col, trunc, year, month\n",
    "\n",
    "# Caminho dos dados CDC do yellow taxi (Parquet)\n",
    "cdc_path = \"abfss://taxi@hfotaxinyc.dfs.core.windows.net/cdc/yellow\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdda8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Tabela bronze: ingestão bruta dos arquivos Parquet do yellow taxi.\"\n",
    ")\n",
    "def bronze_yellow_taxi():\n",
    "    return (\n",
    "        spark.read.format(\"parquet\").load(cdc_path)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447c6b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Tabela silver: dados limpos e padronizados do yellow taxi.\"\n",
    ")\n",
    "@dlt.expect(\"pickup_date_not_null\", \"tpep_pickup_datetime IS NOT NULL\")\n",
    "def silver_yellow_taxi():\n",
    "    df = dlt.read(\"bronze_yellow_taxi\")\n",
    "    return (\n",
    "        df\n",
    "        .withColumn(\"pickup_year_month\", trunc(\"tpep_pickup_datetime\", \"MM\"))\n",
    "        .withColumn(\"pickup_year\", year(\"tpep_pickup_datetime\"))\n",
    "        .withColumn(\"pickup_month\", month(\"tpep_pickup_datetime\"))\n",
    "        .filter(col(\"passenger_count\") > 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4439af70",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table(\n",
    "  comment=\"Tabela gold: agregação de corridas e receita por mês.\"\n",
    ")\n",
    "def gold_yellow_taxi_monthly():\n",
    "    df = dlt.read(\"silver_yellow_taxi\")\n",
    "    return (\n",
    "        df.groupBy(\"pickup_year\", \"pickup_month\")\n",
    "          .agg(\n",
    "              {\"*\": \"count\", \"total_amount\": \"sum\"}\n",
    "          )\n",
    "          .withColumnRenamed(\"count(1)\", \"num_trips\")\n",
    "          .withColumnRenamed(\"sum(total_amount)\", \"total_revenue\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57240954",
   "metadata": {},
   "source": [
    "## Como executar este notebook\n",
    "\n",
    "1. Crie um pipeline Delta Live Tables no Databricks e aponte para este notebook.\n",
    "2. Execute o pipeline para ver as tabelas bronze, silver e gold sendo criadas e atualizadas automaticamente.\n",
    "3. Use as tabelas gold para análises e dashboards.\n",
    "\n",
    "**DLT** garante qualidade, rastreabilidade e automação no seu pipeline de dados!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
